{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoDL_NASBench.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47ieDn-jNLYd"
      },
      "source": [
        "# Neural Architecture Search using NASBench-101\n",
        "\n",
        "This notebook is based on papers https://arxiv.org/abs/1902.09635 and https://arxiv.org/abs/1903.11059\n",
        "and the code is partially taken from notebook at: https://github.com/google-research/nasbench. Helper script is assembled from code using code from https://github.com/romulus0914/NASBench-PyTorch\n",
        "\n",
        "NASBench-101 is a dataset of CNN architectures that are evaluated on CIFAR-10 dataset for different number of epochs. \n",
        "\n",
        "The goal of this notebook is \n",
        "1. To compare performance of different search algorithms for this dataset. \n",
        "2. To gain some insights about this dataset. \n",
        "3. To compare performance of sampled architectures on some other dataset compared to its performance on CIFAR-10. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDKeHonT9v7w"
      },
      "source": [
        "#standard imports\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import collections\n",
        "import math\n",
        "\n",
        "#Pytorch imports\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#get nn_generation from github and import it\n",
        "# !git clone https://github.com/akashjorss/NAS_Search_using_NASBench-101.git\n",
        "# !cp ./NAS_Search_using_NASBench-101/nn_generation.py .\n",
        "import nn_generation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvjSC6uADID"
      },
      "source": [
        "#Mount google drive to import the dataset(Should be done only for imagennette dataset)\n",
        "from google.colab import drive\n",
        "ROOT = \"/content/drive\"\n",
        "drive.mount(ROOT)\n",
        "PROJ = \"My Drive/DL_course/DL_Project/\" # This is a custom path.\n",
        "PROJECT_PATH = os.path.join(ROOT, PROJ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBNMsBUS3SAq"
      },
      "source": [
        "### Load NASBench library and dataset\n",
        "This dataset has accuracies of ~0.5 million sampled architectures. Each architecture is trained for 12, 36 and 108 epochs on CIFAR-10 dataset. For each epoch, the architecture is trained 3 times with different random initializations. Thus, we have a rich dataset of which we can make use of in our own project. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl1oLYux3FhJ"
      },
      "source": [
        "# This code was written in TF 1.12 but should be supported all the way through\n",
        "# TF 1.15. Untested in TF 2.0+.\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# Download the raw data (only 108 epoch data points, for full dataset,\n",
        "# uncomment the second line for nasbench_full.tfrecord).\n",
        "\n",
        "# !curl -O https://storage.googleapis.com/nasbench/nasbench_only108.tfrecord\n",
        "# !curl -O https://storage.googleapis.com/nasbench/nasbench_full.tfrecord\n",
        "\n",
        "# Clone and install the code and dependencies.\n",
        "\n",
        "!git clone https://github.com/google-research/nasbench\n",
        "!pip install ./nasbench\n",
        "!pip install absl-py\n",
        "# Initialize the NASBench object which parses the raw data into memory (this\n",
        "# should only be run once as it takes up to a few minutes).\n",
        "from nasbench import api\n",
        "\n",
        "# Use nasbench_full.tfrecord for full dataset (run download command above).\n",
        "nasbench = api.NASBench(os.path.join(PROJECT_PATH, 'nasbench_full.tfrecord'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6seSxuJ20XV"
      },
      "source": [
        "### Cell in NASBench-101.\n",
        "Cell is the smallest unit of the neural network architecture. It is similar to inception like cell. Below, we define the various constants which would be useful for us in cell definition. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFhFRmck7NzM"
      },
      "source": [
        "# Useful constants\n",
        "INPUT = 'input'\n",
        "OUTPUT = 'output'\n",
        "CONV3X3 = 'conv3x3-bn-relu'\n",
        "CONV1X1 = 'conv1x1-bn-relu'\n",
        "MAXPOOL3X3 = 'maxpool3x3'\n",
        "NUM_VERTICES = 7\n",
        "MAX_EDGES = 9\n",
        "EDGE_SPOTS = NUM_VERTICES * (NUM_VERTICES - 1) / 2   # Upper triangular matrix\n",
        "OP_SPOTS = NUM_VERTICES - 2   # Input/output vertices are fixed\n",
        "ALLOWED_OPS = [CONV3X3, CONV1X1, MAXPOOL3X3]\n",
        "ALLOWED_EDGES = [0, 1]   # Binary adjacency matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llC2AebQOWq9"
      },
      "source": [
        "### Basic usage\n",
        "Write a little descriptions of how cells work!\n",
        "We define cell as a graph, with binary adjacency matrix. The vertices are defined in the ops list. The matrix is an upper triangular matrix to make sure that our graph is a DAG. (include a picture). The boolean value at index (i,j) in matrix tells us if there is a directed edge from ops[i] to ops[j]. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZvm6i0VGP_M"
      },
      "source": [
        "# Query an Inception-like cell from the dataset.\n",
        "cell = api.ModelSpec(\n",
        "  matrix= [[0, 1, 0, 0, 0, 0, 0],\n",
        "          [0, 0, 0, 0, 0, 0, 1],\n",
        "          [0, 0, 0, 0, 0, 0, 1],\n",
        "          [0, 0, 0, 0, 1, 0, 0],\n",
        "          [0, 0, 0, 0, 0, 0, 1],\n",
        "          [0, 0, 0, 0, 0, 0, 1],\n",
        "          [0, 0, 0, 0, 0, 0, 0]],\n",
        "  # Operations at the vertices of the module, matches order of matrix.\n",
        "  ops=[INPUT, CONV1X1, CONV3X3, CONV3X3, CONV3X3, MAXPOOL3X3, OUTPUT])\n",
        "\n",
        "# Querying multiple times may yield different results. Each cell is evaluated 3\n",
        "# times at each epoch budget and querying will sample one randomly.\n",
        "data = nasbench.query(cell, epochs=12)\n",
        "for k, v in data.items():\n",
        "  print('%s: %s' % (k, str(v)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM1S7LmHBJQi"
      },
      "source": [
        "We write a Cell class to make our code more compact. This would have useful functions for tree search. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8SHSoGZIzAD"
      },
      "source": [
        "class Cell:\n",
        "    def __init__(self, matrix = None, ops = None):\n",
        "      spec = None\n",
        "      if matrix is None:\n",
        "        spec = self.initialize()\n",
        "        while not(nasbench.is_valid(spec)):\n",
        "          spec = self.initialize()\n",
        "      else:\n",
        "        self.matrix = matrix\n",
        "        self.ops = ops\n",
        "       \n",
        "    def initialize(self):\n",
        "      self.matrix = np.random.choice(ALLOWED_EDGES, size=(NUM_VERTICES, NUM_VERTICES))\n",
        "      self.matrix = np.triu(self.matrix, 1)\n",
        "      self.ops = np.random.choice(ALLOWED_OPS, size=(NUM_VERTICES)).tolist()\n",
        "      self.ops[0] = INPUT\n",
        "      self.ops[-1] = OUTPUT\n",
        "      return api.ModelSpec(matrix=self.matrix, ops=self.ops)\n",
        "\n",
        "    def get_id(self):\n",
        "      \"\"\"This generates a string which is a unique identifier for our cell\"\"\"\n",
        "      id = \"\"\n",
        "      for i in range(self.matrix.shape[0]):\n",
        "        for j in range(i+1, self.matrix.shape[1]):\n",
        "          id += str(self.matrix[i][j])\n",
        "      for i in range(1, len(self.ops)-1):\n",
        "        id += \" \"\n",
        "        id += str(self.ops[i])\n",
        "      return id\n",
        "    \n",
        "    def invert(self, x):\n",
        "      \"\"\"This toggles the value of boolean value x\"\"\"\n",
        "      if x == 0:\n",
        "        return 1\n",
        "      else:\n",
        "        return 0\n",
        "\n",
        "    def get_children(self): \n",
        "      \"\"\"Generates all the possible children by changing one bit in a cell\"\"\"\n",
        "      children = []\n",
        "      #generate all the combinations after changing one bit\n",
        "      for i in range(self.matrix.shape[0]):\n",
        "        for j in range(i+1, self.matrix.shape[1]):\n",
        "          child_matrix = np.copy(self.matrix)\n",
        "          child_matrix[i][j] = self.invert(child_matrix[i][j])\n",
        "          if nasbench.is_valid(api.ModelSpec(matrix=child_matrix, ops=self.ops)):\n",
        "            children.append(Cell(child_matrix, self.ops))\n",
        "            \n",
        "\n",
        "      for i in range(1, len(self.ops)-1):\n",
        "        child_ops = self.ops.copy()\n",
        "        allowed_ops = ALLOWED_OPS.copy()\n",
        "        allowed_ops.remove(child_ops[i])\n",
        "        child_ops[i] = np.random.choice(allowed_ops)\n",
        "        if nasbench.is_valid(api.ModelSpec(matrix=self.matrix, ops=child_ops)):\n",
        "          children.append(Cell(self.matrix, child_ops))\n",
        "      \n",
        "      return children\n",
        "\n",
        "    def __str__(self):\n",
        "      return self.get_id()\n",
        "    \n",
        "    @classmethod\n",
        "    def construct_from_id(cls, cell_id):\n",
        "      \"\"\"Construct cell from id\"\"\"\n",
        "      assert(type(cell_id) is str)\n",
        "      matrix_str = cell_id.split(\" \")[0]\n",
        "      \n",
        "      #create the cell matrix\n",
        "      idx = 0\n",
        "      matrix = np.zeros((7,7)).astype(int)\n",
        "      for i in range(matrix.shape[0]):\n",
        "        for j in range(i+1, matrix.shape[1]):\n",
        "          matrix[i][j] = int(matrix_str[idx])\n",
        "          idx += 1\n",
        "\n",
        "      #create list of operations    \n",
        "      ops = [INPUT]\n",
        "      for op in cell_id.split(\" \")[1:]:\n",
        "        ops.append(op)\n",
        "      ops.append(OUTPUT)\n",
        "\n",
        "      return cls(matrix, ops)\n",
        "\n",
        "    def get_test_accuracy(self, epochs, quick=True):\n",
        "      spec = api.ModelSpec(self.matrix, self.ops)\n",
        "      #There are 3 measurements and we want to return average\n",
        "      acc = nasbench.query(spec, epochs=epochs)['test_accuracy']\n",
        "      if quick:\n",
        "        return acc\n",
        "      accuracies = []\n",
        "      while len(accuracies) < 3:\n",
        "        if acc not in accuracies:\n",
        "          accuracies.append(acc)\n",
        "        acc = nasbench.query(spec, epochs=epochs)['test_accuracy']\n",
        "      return np.average(np.array(accuracies))\n",
        "\n",
        "\n",
        "    def get_val_accuracy(self, epochs, quick=True):\n",
        "      spec = api.ModelSpec(self.matrix, self.ops)\n",
        "      acc = nasbench.query(spec, epochs=epochs)['validation_accuracy']\n",
        "      if quick:\n",
        "        return acc\n",
        "      accuracies = []\n",
        "      while len(accuracies) < 3:\n",
        "        if acc not in accuracies:\n",
        "          accuracies.append(acc)\n",
        "        acc = nasbench.query(spec, epochs=epochs)['validation_accuracy']\n",
        "      return np.average(np.array(accuracies))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6DR5t8Q4eNk"
      },
      "source": [
        "#Testing cell class\n",
        "cell = Cell()\n",
        "print(cell.matrix)\n",
        "print(cell.ops)\n",
        "print(cell.get_id()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxoXA2mmV70-"
      },
      "source": [
        "We make a class for Tree search with all the useful functions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTs02hr_DWqe"
      },
      "source": [
        "class TreeSearch:\n",
        "  def __init__(self, epochs, time_budget=np.inf, C = 1, num_cells = np.inf):\n",
        "    self.visited = dict({'terminal':0}) #count for e\bach cell\n",
        "    self.root = Cell() #initialize a random cell\n",
        "    self.best_cell = self.root\n",
        "    self.best_valids = [self.best_cell.get_val_accuracy(epochs)] #array of best acuracies so far\n",
        "    self.best_tests = [self.best_cell.get_test_accuracy(epochs)]\n",
        "    self.time_budget = float(time_budget) #in seconds\n",
        "    self.times = [0]\n",
        "    self.epochs=epochs\n",
        "    self.C = C #exploration constant for UCB1\n",
        "    self.num_cells = num_cells #number of cells to search\n",
        "\n",
        "  def search(self):\n",
        "    \"\"\"searches the best cell (using validation accuracy) starting from root in given number of time\n",
        "        or by exploring given number of cells\"\"\"\n",
        "    tic = time.time()\n",
        "    while True:\n",
        "      current_cell = self.root\n",
        "      ancestors = dict() #maintain ancestors array to prevent cycles\n",
        "      while True:\n",
        "        key = current_cell.get_id()\n",
        "        ancestors[key] = 1 #access in dict is faster than in list\n",
        "        if key in self.visited:\n",
        "          self.visited[key] += 1 \n",
        "        else:\n",
        "          self.visited[key] = 1\n",
        "        best_child = self.get_best_child(current_cell, ancestors)\n",
        "\n",
        "        if best_child == None or best_child == 'terminal': \n",
        "          self.visited['terminal'] += 1\n",
        "          break \n",
        "\n",
        "        best_child_acc = best_child.get_val_accuracy(self.epochs)\n",
        "        if best_child_acc > self.best_valids[-1]:\n",
        "          self.best_cell = best_child\n",
        "          self.best_valids.append(best_child_acc)\n",
        "          self.best_tests.append(best_child.get_test_accuracy(self.epochs))\n",
        "        else:\n",
        "          self.best_valids.append(self.best_valids[-1])\n",
        "          self.best_tests.append(self.best_tests[-1])\n",
        "        \n",
        "        tac = time.time()\n",
        "        self.times.append(tac-tic)\n",
        "        if tac-tic > self.time_budget or len(self.times) > self.num_cells:\n",
        "          break\n",
        "        current_cell = best_child\n",
        "\n",
        "      tac = time.time()\n",
        "      if tac-tic > self.time_budget or len(self.times) > self.num_cells:\n",
        "        break\n",
        "  \n",
        "  def get_best_child(self, cell, ancestors):\n",
        "    \"\"\"Returns the best child using validation accuracy and UCB1 algorithm\"\"\"\n",
        "\n",
        "    all_children = cell.get_children()\n",
        "\n",
        "    #remove nodes which are ancestors or are invalid\n",
        "    for child in all_children:\n",
        "      if child.get_id() in ancestors:\n",
        "        all_children.remove(child)\n",
        "    \n",
        "    # if there are no more unvisited nodes\n",
        "    if len(all_children) == 0:\n",
        "      return None\n",
        "    \n",
        "    all_children.append('terminal')\n",
        "\n",
        "    all_children_acc = list(map(lambda c: cell.get_val_accuracy(self.epochs) if c == 'terminal' else c.get_val_accuracy(self.epochs), \n",
        "                            all_children))\n",
        "    all_children_n = [] #num of times certain child is visited\n",
        "    for i in range(len(all_children)):\n",
        "      if all_children[i] != 'terminal':\n",
        "        key = all_children[i].get_id()\n",
        "      else:\n",
        "        key == 'terminal'\n",
        "      if key in self.visited:\n",
        "        all_children_n.append(self.visited[key])\n",
        "      else:\n",
        "        all_children_n.append(0)\n",
        "\n",
        "    #ucb1 scores of all children \n",
        "    all_children_ucb1 = []\n",
        "    parent_n = self.visited[cell.get_id()] #num of times parent node has been visited\n",
        "    for i in range(len(all_children)):\n",
        "      ucb1 = all_children_acc[i] + self.C*math.sqrt(2*math.log(parent_n)/(all_children_n[i]+1e-8))\n",
        "      all_children_ucb1.append(ucb1)\n",
        "    \n",
        "    #return best child according to ucb1\n",
        "    best_i = np.argmax(all_children_ucb1)\n",
        "\n",
        "    return all_children[best_i]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAmt1mow6fDD"
      },
      "source": [
        "#Test tree search\n",
        "treeSearch = TreeSearch(epochs = 108, C = 1, time_budget=5)\n",
        "print(\"Starting cell: \", treeSearch.root)\n",
        "treeSearch.search()\n",
        "print(treeSearch.best_cell)\n",
        "# for key in treeSearch.visited:\n",
        "#   print(key, treeSearch.visited[key])\n",
        "\n",
        "print(\"Number of nodes visited: \", len(treeSearch.times) -1)\n",
        "plt.plot(treeSearch.times, treeSearch.best_valids, color='blue')\n",
        "plt.plot(treeSearch.times, treeSearch.best_tests, color='red')\n",
        "plt.xlabel(\"Time spent (seconds)\")\n",
        "plt.ylabel(\"Accuracy on CIFAR10 (108 epochs)\")\n",
        "plt.title(\"Validation Accuracy(Blue) and Test Accuracy(Red)\")\n",
        "plt.ylim(0.9, 0.96)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXnVdG32Oe19"
      },
      "source": [
        "### Below are the functions for Random Search and Evolution Search (Created by NASBench-101 Team). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtl_Aqr7OeOF"
      },
      "source": [
        "def random_spec():\n",
        "  \"\"\"Returns a random valid spec.\"\"\"\n",
        "  while True:\n",
        "    matrix = np.random.choice(ALLOWED_EDGES, size=(NUM_VERTICES, NUM_VERTICES))\n",
        "    matrix = np.triu(matrix, 1)\n",
        "    ops = np.random.choice(ALLOWED_OPS, size=(NUM_VERTICES)).tolist()\n",
        "    ops[0] = INPUT\n",
        "    ops[-1] = OUTPUT\n",
        "    spec = api.ModelSpec(matrix=matrix, ops=ops)\n",
        "    if nasbench.is_valid(spec):\n",
        "      return spec\n",
        "\n",
        "def mutate_spec(old_spec, mutation_rate=1.0):\n",
        "  \"\"\"Computes a valid mutated spec from the old_spec.\"\"\"\n",
        "  while True:\n",
        "    new_matrix = copy.deepcopy(old_spec.original_matrix) #-> deep copy?\n",
        "    new_ops = copy.deepcopy(old_spec.original_ops)\n",
        "\n",
        "    # In expectation, V edges flipped (note that most end up being pruned).\n",
        "    edge_mutation_prob = mutation_rate / NUM_VERTICES\n",
        "    for src in range(0, NUM_VERTICES - 1):\n",
        "      for dst in range(src + 1, NUM_VERTICES):\n",
        "        if random.random() < edge_mutation_prob:\n",
        "          new_matrix[src, dst] = 1 - new_matrix[src, dst]\n",
        "          \n",
        "    # In expectation, one op is resampled.\n",
        "    op_mutation_prob = mutation_rate / OP_SPOTS\n",
        "    for ind in range(1, NUM_VERTICES - 1):\n",
        "      if random.random() < op_mutation_prob:\n",
        "        available = [o for o in nasbench.config['available_ops'] if o != new_ops[ind]]\n",
        "        new_ops[ind] = random.choice(available)\n",
        "        \n",
        "    new_spec = api.ModelSpec(new_matrix, new_ops)\n",
        "    if nasbench.is_valid(new_spec):\n",
        "      return new_spec\n",
        "\n",
        "def random_combination(iterable, sample_size):\n",
        "  \"\"\"Random selection from itertools.combinations(iterable, r).\"\"\"\n",
        "  pool = tuple(iterable)\n",
        "  n = len(pool)\n",
        "  indices = sorted(random.sample(range(n), sample_size))\n",
        "  return tuple(pool[i] for i in indices)\n",
        "\n",
        "def run_random_search(max_time_budget=5e6, num_cells=np.inf):\n",
        "  \"\"\"Run a single roll-out of random search to a fixed time budget.\"\"\"\n",
        "  nasbench.reset_budget_counters()\n",
        "  times, best_valids, best_tests = [0.0], [0.0], [0.0]\n",
        "  while True:\n",
        "    spec = random_spec()\n",
        "    data = nasbench.query(spec, epochs=108)\n",
        "\n",
        "    # It's important to select models only based on validation accuracy, test\n",
        "    # accuracy is used only for comparing different search trajectories.\n",
        "    if data['validation_accuracy'] > best_valids[-1]:\n",
        "      best_valids.append(data['validation_accuracy'])\n",
        "      best_tests.append(data['test_accuracy'])\n",
        "    else:\n",
        "      best_valids.append(best_valids[-1])\n",
        "      best_tests.append(best_tests[-1])\n",
        "\n",
        "    time_spent, _ = nasbench.get_budget_counters()\n",
        "    times.append(time_spent)\n",
        "    if time_spent > max_time_budget or len(times) > num_cells:\n",
        "      # Break the first time we exceed the budget.\n",
        "      break\n",
        "\n",
        "  return times, best_valids, best_tests\n",
        "\n",
        "def run_evolution_search(max_time_budget=5e6,\n",
        "                         num_cells = np.inf,\n",
        "                         population_size=50,\n",
        "                         tournament_size=10,\n",
        "                         mutation_rate=1.0):\n",
        "  \"\"\"Run a single roll-out of regularized evolution to a fixed time budget.\"\"\"\n",
        "  nasbench.reset_budget_counters()\n",
        "  times, best_valids, best_tests = [0.0], [0.0], [0.0]\n",
        "  population = []   # (validation, spec) tuples\n",
        "\n",
        "  # For the first population_size individuals, seed the population with randomly\n",
        "  # generated cells.\n",
        "  for _ in range(population_size):\n",
        "    spec = random_spec()\n",
        "    data = nasbench.query(spec)\n",
        "    time_spent, _ = nasbench.get_budget_counters()\n",
        "    times.append(time_spent)\n",
        "    population.append((data['validation_accuracy'], spec))\n",
        "\n",
        "    if data['validation_accuracy'] > best_valids[-1]:\n",
        "      best_valids.append(data['validation_accuracy'])\n",
        "      best_tests.append(data['test_accuracy'])\n",
        "    else:\n",
        "      best_valids.append(best_valids[-1])\n",
        "      best_tests.append(best_tests[-1])\n",
        "\n",
        "    if time_spent > max_time_budget or len(times) > num_cells:\n",
        "      break\n",
        "\n",
        "  # After the population is seeded, proceed with evolving the population.\n",
        "  while True:\n",
        "    sample = random_combination(population, tournament_size)\n",
        "    best_spec = sorted(sample, key=lambda i:i[0])[-1][1]\n",
        "    new_spec = mutate_spec(best_spec, mutation_rate)\n",
        "\n",
        "    data = nasbench.query(new_spec)\n",
        "    time_spent, _ = nasbench.get_budget_counters()\n",
        "    times.append(time_spent)\n",
        "\n",
        "    # In regularized evolution, we kill the oldest individual in the population.\n",
        "    population.append((data['validation_accuracy'], new_spec))\n",
        "    population.pop(0)\n",
        "\n",
        "    if data['validation_accuracy'] > best_valids[-1]:\n",
        "      best_valids.append(data['validation_accuracy'])\n",
        "      best_tests.append(data['test_accuracy'])\n",
        "    else:\n",
        "      best_valids.append(best_valids[-1])\n",
        "      best_tests.append(best_tests[-1])\n",
        "\n",
        "    if time_spent > max_time_budget or len(times) > num_cells:\n",
        "      break\n",
        "\n",
        "  return times, best_valids, best_tests\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPA0NO-R75vh"
      },
      "source": [
        "### Search Experiment\n",
        "In the following section we compare performance of different search algorithms on NASBench-101 dataset. We can compare them with the time, and by number of nodes visited. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMfF2zXxpQNA"
      },
      "source": [
        "# Run random search and evolution search 10 times each. This should take a few\n",
        "# minutes to run. Note that each run would have taken days of compute to\n",
        "# actually train and evaluate if the dataset were not precomputed.\n",
        "random_data = []\n",
        "evolution_data = []\n",
        "tree_search_data = []\n",
        "for repeat in range(10):\n",
        "  print('Running repeat %d' % (repeat + 1))\n",
        "  times, best_valid, best_test = run_random_search(max_time_budget = 5e6, num_cells=np.inf)\n",
        "  # normalize time between 0 and 5e6\n",
        "  # times = np.array(times)\n",
        "  # times = 5e6*(times - np.min(times))/ (np.max(times) - np.min(times))\n",
        "  random_data.append((list(times), best_valid, best_test))\n",
        "\n",
        "  times, best_valid, best_test = run_evolution_search(max_time_budget = 5e6, num_cells=np.inf)\n",
        "  # normalize time between 0 and 5e6\n",
        "  # times = np.array(times)\n",
        "  # times = 5e6*(times - np.min(times))/ (np.max(times) - np.min(times))\n",
        "  evolution_data.append((times, best_valid, best_test))\n",
        "  \n",
        "  tree_search = TreeSearch(epochs = 108, time_budget = 5, num_cells=np.inf)\n",
        "  tree_search.search()\n",
        "  times, best_valid, best_test = tree_search.times, tree_search.best_valids, tree_search.best_tests\n",
        "  # normalize time between 0 and 5e6\n",
        "  times = np.array([t*1e6 for t in times])\n",
        "  # times = 5e6*(times - np.min(times))/ (np.max(times) - np.min(times))\n",
        "\n",
        "  tree_search_data.append((list(times), best_valid, best_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d-yRmuhkz35"
      },
      "source": [
        "#Plot how the validation changes with time\n",
        "plt.figure(figsize=(20, 5))\n",
        "xlabel = 'time spent (seconds)' \n",
        "plt.subplot(1, 3, 1)\n",
        "for times, best_valid, best_test in random_data:\n",
        "  plt.plot(times, best_valid, label='valid', color='red', alpha=0.5) #range(1, len(times)+1)\n",
        "  plt.plot(times, best_test, label='test', color='blue', alpha=0.5)\n",
        "\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel(xlabel)\n",
        "plt.ylim(0.92, 0.96)\n",
        "plt.grid()\n",
        "plt.title('Random search trajectories (red=validation, blue=test)')\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "for times, best_valid, best_test in evolution_data:\n",
        "  plt.plot(times, best_valid, label='valid', color='red', alpha=0.5)\n",
        "  plt.plot(times, best_test, label='test', color='blue', alpha=0.5)\n",
        "\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel(xlabel)\n",
        "plt.ylim(0.92, 0.96)\n",
        "plt.grid()\n",
        "plt.title('Evolution search trajectories (red=validation, blue=test)')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "for times, best_valid, best_test in tree_search_data:\n",
        "  plt.plot(times, best_valid, label='valid', color='red', alpha=0.5)\n",
        "  plt.plot(times, best_test, label='test', color='blue', alpha=0.5)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel(xlabel)\n",
        "plt.ylim(0.92, 0.96)\n",
        "plt.grid()\n",
        "plt.title('Tree search trajectories (red=validation, blue=test)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q078TpI085BE"
      },
      "source": [
        "#Plot how the validation changes with number of cells visited\n",
        "plt.figure(figsize=(20, 5))\n",
        "xlabel = 'number of cells explored'\n",
        "plt.subplot(1, 3, 1)\n",
        "for times, best_valid, best_test in random_data:\n",
        "  plt.plot(range(1, len(times)+1), best_valid, label='valid', color='red', alpha=0.5) #range(1, len(times)+1)\n",
        "  plt.plot(range(1, len(times)+1), best_test, label='test', color='blue', alpha=0.5)\n",
        "\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel(xlabel)\n",
        "plt.ylim(0.92, 0.96)\n",
        "plt.grid()\n",
        "plt.title('Random search trajectories (red=validation, blue=test)')\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "for times, best_valid, best_test in evolution_data:\n",
        "  plt.plot(range(1, len(times)+1), best_valid, label='valid', color='red', alpha=0.5)\n",
        "  plt.plot(range(1, len(times)+1), best_test, label='test', color='blue', alpha=0.5)\n",
        "\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel(xlabel)\n",
        "plt.ylim(0.92, 0.96)\n",
        "plt.grid()\n",
        "plt.title('Evolution search trajectories (red=validation, blue=test)')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "for times, best_valid, best_test in tree_search_data:\n",
        "  plt.plot(range(1, len(times)+1), best_valid, label='valid', color='red', alpha=0.5)\n",
        "  plt.plot(range(1, len(times)+1), best_test, label='test', color='blue', alpha=0.5)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel(xlabel)\n",
        "plt.ylim(0.92, 0.96)\n",
        "plt.grid()\n",
        "plt.title('Tree search trajectories (red=validation, blue=test)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9lB_qL2oz9M"
      },
      "source": [
        "# Compare the mean test accuracy along with error bars.\n",
        "def plot_data(data, color, label, gran=10000, max_budget=5e6):\n",
        "  \"\"\"Computes the mean and IQR fixed time steps.\"\"\"\n",
        "  print(len(data))\n",
        "  xs = range(0, int(max_budget+1), gran) #500 \n",
        "  mean = [0.0]\n",
        "  per25 = [0.0]\n",
        "  per75 = [0.0]\n",
        "  \n",
        "  repeats = len(data)\n",
        "  pointers = [1 for _ in range(repeats)]\n",
        "  \n",
        "  cur = gran\n",
        "  while cur < max_budget+1:\n",
        "    all_vals = []\n",
        "    for repeat in range(repeats):\n",
        "      while (pointers[repeat] < len(data[repeat][0]) and \n",
        "             data[repeat][0][pointers[repeat]] < cur):\n",
        "        pointers[repeat] += 1\n",
        "      prev_time = data[repeat][0][pointers[repeat]-1]\n",
        "      prev_test = data[repeat][2][pointers[repeat]-1]\n",
        "      #print(data[repeat][0][:10])\n",
        "      next_time = data[repeat][0][pointers[repeat]]\n",
        "      next_test = data[repeat][2][pointers[repeat]]\n",
        "      assert prev_time < cur and next_time >= cur\n",
        "\n",
        "      # Linearly interpolate the test between the two surrounding points\n",
        "      cur_val = ((cur - prev_time) / (next_time - prev_time)) * (next_test - prev_test) + prev_test\n",
        "      \n",
        "      all_vals.append(cur_val)\n",
        "      \n",
        "    all_vals = sorted(all_vals)\n",
        "    mean.append(sum(all_vals) / float(len(all_vals)))\n",
        "    per25.append(all_vals[int(0.25 * repeats)])\n",
        "    per75.append(all_vals[int(0.75 * repeats)])\n",
        "      \n",
        "    cur += gran\n",
        "    \n",
        "  plt.plot(xs, mean, color=color, label=label, linewidth=2)\n",
        "  plt.fill_between(xs, per25, per75, alpha=0.1, linewidth=0, facecolor=color)\n",
        "\n",
        "plot_data(random_data, 'red', 'random')\n",
        "plot_data(evolution_data, 'blue', 'evolution')\n",
        "plot_data(tree_search_data, 'green', 'tree search')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0.92, 0.95)\n",
        "plt.xlabel('total training time spent (seconds)') #total number of cells explored = 1000')\n",
        "plt.ylabel('accuracy')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpKMDWfx9Y63"
      },
      "source": [
        "We see that the performance of the tree search is not very satisfactory. One of the reasons is that it is not exploring as many number of cells as random search or evolution search. But even when number of nodes is same, for high enough number of, the performance is not better. \n",
        "\n",
        "Tree Search performs well when we assume that the neighbouring points have similar rewards. So we test this assumption in the following code. \n",
        "\n",
        "Distance between two cells is measured as follows:\n",
        " 1. We generate edge triplets (Node1, edge, Node2)  for each cell, as cell is a DAG. \n",
        " 2. Distance is how many tuples are in cell1 that are not in cell2, plus the size difference between cell1 and cell2. \n",
        "\n",
        "The distance is commutative. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtM2pnJ_gir-"
      },
      "source": [
        "#find difference b/w two cells\n",
        "def find_dist(cell1, cell2):\n",
        "  \"\"\"returns the distance between cell1 and cell2\"\"\"\n",
        "  \n",
        "  def gen_graph_tuple(cell):\n",
        "    \"\"\"generate tuples of connected nodes\"\"\"\n",
        "    graph = []\n",
        "    for i in range(cell.matrix.shape[0]):\n",
        "      for j in range(i, cell.matrix.shape[1]):\n",
        "        if cell.matrix[i][j] == 1:\n",
        "          graph.append((cell.ops[i], cell.ops[j]))\n",
        "    return graph\n",
        "\n",
        "  cell1_graph = gen_graph_tuple(cell1)\n",
        "  cell2_graph = gen_graph_tuple(cell2)\n",
        "\n",
        "  # print(cell1_graph)\n",
        "  # print(cell2_graph)\n",
        "\n",
        "  #find distance between cell1 and cell2\n",
        "  distance = 0\n",
        "  num_edges_cell1 = len(cell1_graph)\n",
        "  num_edges_cell2 = len(cell2_graph)\n",
        "  for edge in cell1_graph:\n",
        "    # print(edge)\n",
        "    if edge not in cell2_graph:\n",
        "      distance += 1\n",
        "    else:\n",
        "      cell2_graph.remove(edge)\n",
        "\n",
        "  if num_edges_cell1 < num_edges_cell2:\n",
        "    distance += (num_edges_cell2 - num_edges_cell1)\n",
        "\n",
        "  return distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnxCV57X_qRi"
      },
      "source": [
        "As seen in the figure below, there is not a high correlation between distance and performance of CNN of composed of cells. That means, similar cells, don't necessarily yield similar accuracies. (So, tree search is not a good search algorithm for this dataset). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgnCerp-jbmv"
      },
      "source": [
        "#radomly sample the cells and compare their accuracies\n",
        "from tqdm import tqdm\n",
        "distances, diff_accuracies = [], []\n",
        "for runs in range(1000):\n",
        "  cell1 = Cell()\n",
        "  cell2 = Cell()\n",
        "  distances.append(find_dist(cell1, cell2))\n",
        "  diff_accuracies.append(abs(cell1.get_val_accuracy(108, quick=True) - cell2.get_val_accuracy(108, quick=True)))\n",
        "\n",
        "plt.scatter(distances, diff_accuracies)\n",
        "plt.title(\"Distance vs Accuracy between 2 randomly sampled architectures\")\n",
        "plt.xlabel(\"distance\")\n",
        "plt.ylabel(\"Validation accuracy (108 epochs) on CIFAR10\")\n",
        "plt.show()\n",
        "from scipy.stats import pearsonr\n",
        "print(\"pearson correlation is \", pearsonr(distances, diff_accuracies)[0])\n",
        "print(\"p value \", pearsonr(distances, diff_accuracies)[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEFFyjTGB_p3"
      },
      "source": [
        "### Training the sampled architecture using our own dataset. \n",
        "Following are the functions useful for training randomly sampled architecture on Fashion MNIST data. \n",
        "We want to compare the performance of same architecutres on CIFAR-10 and some other dataset. Basically, we are trying to find out if the work done by NASBench-101 of training ~0.5m architectures can be useful to us for our own datasets. \n",
        "We choose FashionMNIST because:\n",
        "1. It is very different from CIFAR-10 on which NASBench dataset is trained. (grayscale, about clothes)\n",
        "2. It is not as simple as overused MNIST data. But simple enough to achieve good accuracy in low number of epochs. (~6 epochs)\n",
        "3. Images are not big in size so many neural networks can be trained with the limited resources we have. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuNrIonZl44L"
      },
      "source": [
        "def Train(net, trainloader, num_trains, args):\n",
        "    num_epochs = args.epochs\n",
        "    batch_size = args.batch_size\n",
        "    lr = args.learning_rate\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=args.learning_rate, momentum=args.momentum, weight_decay=args.weight_decay)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # forward\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            # back-propagation\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), args.grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predict = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predict.eq(targets.data).cpu().sum().item()\n",
        "            if batch_idx % 100 == 0:\n",
        "              print('Epoch=%d Batch=%d | Loss=%.3f, Acc=%.3f(%d/%d)' %\n",
        "                    (epoch, batch_idx+1, train_loss/(batch_idx+1), correct/total, correct, total))\n",
        "\n",
        "def Test(net, testloader, num_tests, predict_net=None):\n",
        "    net.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            _, predict = torch.max(outputs.data, 1)\n",
        "            correct += predict.eq(targets.data).cpu().sum().item()\n",
        "\n",
        "        test_loss = test_loss/len(testloader)\n",
        "        accuracy = correct/num_tests\n",
        "        print('Testing: Loss=%.3f, Acc=%.3f(%d/%d)' %\n",
        "              (test_loss, accuracy, correct, num_tests))\n",
        "\n",
        "        return accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWfqK2tM9r3K"
      },
      "source": [
        "def PrepareDataset(batch_size):\n",
        "    print('--- Preparing Fashion MNIST Data ---')\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Pad(2), #convert to shape [32,32]\n",
        "        # transforms.Normalize((0.2860), (0.3205)), #no need to normalize fashion mnist\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Pad(2),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=test_transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
        "\n",
        "    print('--- Fashion MNIST Data Prepared ---')\n",
        "\n",
        "    return trainloader, len(trainset), testloader, len(testset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yum1n9U-svFA"
      },
      "source": [
        "#arguments of nn architecture\n",
        "args = nn_generation.CustomDict()\n",
        "args['module_vertices'] = 7\n",
        "args['max_edges'] = 9\n",
        "args['available_ops'] = ['conv3x3-bn-relu', 'conv1x1-bn-relu', 'maxpool3x3']\n",
        "args['stem_out_channels'] = 128\n",
        "args['num_stacks'] = 3\n",
        "args['num_modules_per_stack'] = 3\n",
        "args['batch_size'] = 128\n",
        "args['epochs'] = 6\n",
        "args['learning_rate'] = 0.025\n",
        "args['lr_decay_method'] = 'COSINE_BY_STEP'\n",
        "args['momentum'] = 0.9\n",
        "args['weight_decay'] = 1e-4\n",
        "args['grad_clip'] = 5\n",
        "args['num_labels'] = 10\n",
        "args['in_channels'] = 1 #For FashionMNIST\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZycNtvhXf_rR"
      },
      "source": [
        "#randomly sample the cells. Train neural network on mnist. Compare accuracies(cifer and mnist)\n",
        "#of sampled neural network \n",
        "import os\n",
        "device = 'cuda'\n",
        "#Download Fashion MNIST Data\n",
        "#To Do\n",
        "trainloader, num_train, testloader, num_test = PrepareDataset(batch_size = 128)\n",
        "\n",
        "#Load previous made accuracies df\n",
        "accuracies_df = pd.read_csv(\"NAS_Search_using_NASBench-101/accuracies.csv\").drop('Unnamed: 0', axis=1)\n",
        "print(accuracies_df)\n",
        "#load previously sampled architectures\n",
        "sampled_cells = list(accuracies_df['cell'].values)\n",
        "\n",
        "#train ~100 architectures \n",
        "for _ in range(100):\n",
        "  cell = Cell()\n",
        "  while cell in sampled_cells:\n",
        "    cell = Cell()\n",
        "  \n",
        "\n",
        "  spec = api.ModelSpec(cell.matrix, cell.ops) \n",
        "  net = nn_generation.generate_net(spec, args) \n",
        "  net = net.to(device)\n",
        "\n",
        "  Train(net, trainloader, num_train, args)\n",
        "  mnist_test_acc = Test(net, testloader, num_test)\n",
        "\n",
        "  accuracies = {'cifar_acc_12': cell.get_test_accuracy(12), \n",
        "                'cifar_acc_36': cell.get_test_accuracy(36),\n",
        "                'cifar_acc_108': cell.get_test_accuracy(108),\n",
        "                'mnist_test_acc': mnist_test_acc, \n",
        "              'cell': cell.get_id()}\n",
        "\n",
        "  accuracies_df = accuracies_df.append(accuracies, ignore_index=True)\n",
        "  print(accuracies_df)\n",
        "\n",
        "  accuracies_df.to_csv(\"NAS_Search_using_NASBench-101/accuracies.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYCgptkQvDCK"
      },
      "source": [
        "#Compute pearson correlation between accuracies of mnist and cifar\n",
        "from scipy.stats import pearsonr\n",
        "import matplotlib.pyplot as plt\n",
        "#load the dataframe\n",
        "accuracies_df = pd.read_csv(os.path.join(PROJECT_PATH, \"accuracies.csv\")).drop('Unnamed: 0', axis=1)\n",
        "\n",
        "mnist_acc = accuracies_df['mnist_test_acc']\n",
        "EPOCHS = [12, 36, 108]\n",
        "for epoch in EPOCHS:\n",
        "  cifar_acc = accuracies_df['cifar_acc_'+str(epoch)]\n",
        "  plt.scatter(mnist_acc, cifar_acc)\n",
        "  plt.title(\"Randomly sampled model architecture accuracies (143 samples)\")\n",
        "  plt.xlabel(\"Cifar10 test accuracy (\" + str(epoch) +\" epochs)\")  \n",
        "  plt.ylabel(\"Fashion MNIST test accuracy\")\n",
        "  plt.show()\n",
        "  r, p = pearsonr(mnist_acc, cifar_acc)\n",
        "  print(\"pearson correlation: \", r)\n",
        "  print(\"p value: \", p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvtH-4gTE6WX"
      },
      "source": [
        "We notice that the performance of sampled architectures are highly correlated. The correlation is higher with large number of epochs, as network reaches more stability. \n",
        "\n",
        "This is a good news! If good architectures perform well on multiple datasets, it could give us a good starting point when we are selecting architecture for our own CNN project. \n",
        "\n",
        "We need to test the correlation between other datasets though before we can make any generalizations. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPnRtp0zXUDh"
      },
      "source": [
        "To do:\n",
        "1. Validate the CIFAR10 accuracies on the sampled architectures. \n",
        "2. Test our prediction on Imagennete dataset. (Different sized inputs). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7qlt5VfE3_-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}